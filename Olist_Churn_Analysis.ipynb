{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Olist Customer Churn Analysis\n",
        "This notebook performs churn prediction using PySpark and Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when, count, avg\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Olist Churn Analysis\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "orders = spark.read.csv(\"D:/Krishna/LPU/SEM 7/INT315/ProjectINT315/ProjectData/olist_orders_dataset.csv\", header=True, inferSchema=True)\n",
        "order_items = spark.read.csv(\"D:/Krishna/LPU/SEM 7/INT315/ProjectINT315/ProjectData/olist_order_items_dataset.csv\", header=True, inferSchema=True)\n",
        "customers = spark.read.csv(\"D:/Krishna/LPU/SEM 7/INT315/ProjectINT315/ProjectData/olist_customers_dataset.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "orders = orders.dropna(subset=['customer_id', 'order_id', 'order_status'])\n",
        "order_items = order_items.dropna(subset=['order_id', 'price'])\n",
        "customers = customers.dropna(subset=['customer_id'])\n",
        "orders = orders.filter(col(\"order_status\").isin([\"delivered\", \"canceled\", \"unavailable\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Join Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "order_items = order_items.withColumnRenamed(\"order_id\", \"order_id_item\")\n",
        "data = orders.join(order_items, orders.order_id == order_items.order_id_item, \"inner\")\n",
        "data = data.join(customers, on=\"customer_id\", how=\"inner\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customer_orders = data.groupBy(\"customer_id\", \"customer_state\").agg(\n",
        "    count(\"order_id\").alias(\"order_count\"),\n",
        "    avg(\"price\").alias(\"avg_order_price\")\n",
        ")\n",
        "\n",
        "churn_data = orders.groupBy(\"customer_id\").agg(\n",
        "    when(count(when(col(\"order_status\") == \"delivered\", True)) > 0, 0).otherwise(1).alias(\"churned\")\n",
        ")\n",
        "\n",
        "final_data = customer_orders.join(churn_data, on=\"customer_id\", how=\"inner\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Encode Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state_indexer = StringIndexer(inputCol=\"customer_state\", outputCol=\"customer_state_index\")\n",
        "final_data = state_indexer.fit(final_data).transform(final_data)\n",
        "\n",
        "encoder = OneHotEncoder(inputCols=[\"customer_state_index\"], outputCols=[\"customer_state_vec\"])\n",
        "final_data = encoder.fit(final_data).transform(final_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assemble Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"order_count\", \"avg_order_price\", \"customer_state_vec\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "assembled_data = assembler.transform(final_data).select(\"features\", \"churned\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Test Split & Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data, test_data = assembled_data.randomSplit([0.8, 0.2], seed=42)\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"churned\")\n",
        "model = lr.fit(train_data)\n",
        "predictions = model.transform(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluator_auc = BinaryClassificationEvaluator(labelCol=\"churned\", metricName=\"areaUnderROC\")\n",
        "auc = evaluator_auc.evaluate(predictions)\n",
        "\n",
        "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"churned\", metricName=\"accuracy\")\n",
        "accuracy = evaluator_acc.evaluate(predictions)\n",
        "\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"churned\", metricName=\"f1\")\n",
        "f1_score = evaluator_f1.evaluate(predictions)\n",
        "\n",
        "print(f\"Model Accuracy : {accuracy:.2f}\")\n",
        "print(f\"Model F1 Score : {f1_score:.2f}\")\n",
        "print(f\"Model AUC      : {auc:.2f}\")\n",
        "print(f\"Coefficients   : {model.coefficients}\")\n",
        "print(f\"Intercept      : {model.intercept}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdf = predictions.select(\"prediction\", \"churned\").toPandas()\n",
        "counts = pdf.groupby([\"churned\", \"prediction\"]).size().unstack(fill_value=0)\n",
        "\n",
        "counts.plot(kind='bar', figsize=(7,5))\n",
        "plt.title(\"Actual vs Predicted Churn\")\n",
        "plt.xlabel(\"Actual Churned\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.legend(title=\"Predicted\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdf_probs = predictions.select(\"probability\", \"churned\").toPandas()\n",
        "pdf_probs[\"prob_churn\"] = pdf_probs[\"probability\"].apply(lambda x: float(x[1]))\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.histplot(data=pdf_probs, x=\"prob_churn\", hue=\"churned\", kde=True, bins=20)\n",
        "plt.title(\"Predicted Churn Probability Distribution\")\n",
        "plt.xlabel(\"Probability of Churn\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}